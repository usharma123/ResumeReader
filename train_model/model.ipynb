{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a86bf885454dc5905e9758f92c6d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 50, but your input_length is only 28. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n",
      "Your max_length is set to 50, but your input_length is only 29. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n",
      "Your max_length is set to 50, but your input_length is only 26. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n",
      "Your max_length is set to 50, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n",
      "Your max_length is set to 50, but your input_length is only 27. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n",
      "Your max_length is set to 50, but your input_length is only 28. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n",
      "Your max_length is set to 50, but your input_length is only 27. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n",
      "Your max_length is set to 50, but your input_length is only 28. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n",
      "Your max_length is set to 50, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n",
      "Your max_length is set to 50, but your input_length is only 27. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n",
      "Your max_length is set to 50, but your input_length is only 32. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=16)\n",
      "Your max_length is set to 50, but your input_length is only 26. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n",
      "Your max_length is set to 50, but your input_length is only 26. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n",
      "Your max_length is set to 50, but your input_length is only 24. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n",
      "Your max_length is set to 50, but your input_length is only 27. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n",
      "Your max_length is set to 50, but your input_length is only 30. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n",
      "Your max_length is set to 50, but your input_length is only 27. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n",
      "Your max_length is set to 50, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n",
      "Your max_length is set to 50, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n",
      "Your max_length is set to 50, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         filename                                   extracted_skills\n",
      "0     resume1.pdf  Software engineer with expertise in Python, Ja...\n",
      "1    resume2.docx  Biomedical engineer with experience in signal ...\n",
      "2     resume3.pdf  Research scientist with a focus on clinical tr...\n",
      "3    resume4.docx  Data scientist proficient in Python, machine l...\n",
      "4     resume5.pdf  Software developer with experience in Java, C+...\n",
      "5     resume6.pdf  Project manager with experience in agile metho...\n",
      "6    resume7.docx   marketing specialist with expertise in digita...\n",
      "7     resume8.pdf  Financial analyst with strong skills in financ...\n",
      "8    resume9.docx  Mechanical engineer with experience in CAD des...\n",
      "9    resume10.pdf  Electrical engineer proficient in circuit desi...\n",
      "10   resume11.pdf  Civil engineer with expertise in structural an...\n",
      "11  resume12.docx  Chemical engineer with experience in process e...\n",
      "12   resume13.pdf  Architect with strong skills in architectural ...\n",
      "13  resume14.docx  HR manager with expertise in recruitment, empl...\n",
      "14   resume15.pdf  Business analyst proficient in data analysis, ...\n",
      "15   resume16.pdf  Graphic designer with skills in Adobe Creative...\n",
      "16  resume17.docx  Healthcare professional with experience in pat...\n",
      "17   resume18.pdf  Environmental scientist with expertise in envi...\n",
      "18  resume19.docx  Teacher with experience in curriculum developm...\n",
      "19   resume20.pdf  Lawyer with expertise in legal research, contr...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "\n",
    "# Load a pre-trained model and tokenizer from the Hugging Face library\n",
    "model_name = \"facebook/bart-large-cnn\"  # Using BART as an example, you can replace it with an appropriate model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Define a pipeline for text generation\n",
    "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Function to extract skills from a resume using the model\n",
    "def extract_skills_from_resume(text):\n",
    "    # Use the model to summarize the text, assuming summarization can help highlight key points (skills)\n",
    "    summary = summarizer(text, max_length=50, min_length=25, do_sample=False)\n",
    "    return summary[0]['summary_text']\n",
    "\n",
    "# Load the annotated sample resumes CSV\n",
    "data = pd.read_csv('/Users/utsavsharma/Desktop/RR/train_model/annotated_sample_resumes_20.csv')\n",
    "\n",
    "# Extract skills for each resume in the CSV\n",
    "data['extracted_skills'] = data['resume_text'].apply(extract_skills_from_resume)\n",
    "\n",
    "# Save the results to a new CSV\n",
    "data.to_csv('resumes_with_extracted_skills.csv', index=False)\n",
    "\n",
    "print(data[['filename', 'extracted_skills']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
